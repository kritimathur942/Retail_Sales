{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4922c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2   \n",
      "0      1  2010-02-05        42.31       2.572        NaN        NaN  \\\n",
      "1      1  2010-02-12        38.51       2.548        NaN        NaN   \n",
      "2      1  2010-02-19        39.93       2.514        NaN        NaN   \n",
      "3      1  2010-02-26        46.63       2.561        NaN        NaN   \n",
      "4      1  2010-03-05        46.50       2.625        NaN        NaN   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
      "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
      "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
      "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
      "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
      "4        NaN        NaN        NaN  211.350143         8.106      False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "features = pd.read_csv('features.csv')\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec327e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store              0\n",
      "Date               0\n",
      "Temperature        0\n",
      "Fuel_Price         0\n",
      "MarkDown1       4158\n",
      "MarkDown2       5269\n",
      "MarkDown3       4577\n",
      "MarkDown4       4726\n",
      "MarkDown5       4140\n",
      "CPI              585\n",
      "Unemployment     585\n",
      "IsHoliday          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = features.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4dae5e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric columns:\n",
      "Index(['Date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Identify non-numeric columns\n",
    "non_numeric_cols = features.select_dtypes(include=['object']).columns\n",
    "print(\"Non-numeric columns:\")\n",
    "print(non_numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7fa38de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to convert non-numeric columns to numeric, coercing errors to NaN\n",
    "features[non_numeric_cols] = features[non_numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "features['Date'] = pd.to_datetime(features['Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "740f3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean of each column\n",
    "features_filled_mean = features.fillna(features.mean())\n",
    "\n",
    "# Or fill missing values with the median of each column\n",
    "features_filled_median = features.fillna(features.median())\n",
    "\n",
    "placeholder_date = pd.Timestamp('2000-01-01')  # Define a placeholder date\n",
    "features['Date'] = features['Date'].fillna(placeholder_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb1f741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store           0\n",
      "Date            0\n",
      "Temperature     0\n",
      "Fuel_Price      0\n",
      "MarkDown1       0\n",
      "MarkDown2       0\n",
      "MarkDown3       0\n",
      "MarkDown4       0\n",
      "MarkDown5       0\n",
      "CPI             0\n",
      "Unemployment    0\n",
      "IsHoliday       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify that there are no missing values left\n",
    "print(features_filled_mean.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1786f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store Type    Size\n",
      "0      1    A  151315\n",
      "1      2    A  202307\n",
      "2      3    B   37392\n",
      "3      4    A  205863\n",
      "4      5    B   34875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "stores = pd.read_csv('stores.csv')\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(stores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6cf5ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Store    0\n",
      "Type     0\n",
      "Size     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = stores.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df8439b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
      "0      1     1  2010-02-05      24924.50      False\n",
      "1      1     1  2010-02-12      46039.49       True\n",
      "2      1     1  2010-02-19      41595.55      False\n",
      "3      1     1  2010-02-26      19403.54      False\n",
      "4      1     1  2010-03-05      21827.90      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Print the first few rows of the dataset\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83773be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Store           0\n",
      "Dept            0\n",
      "Date            0\n",
      "Weekly_Sales    0\n",
      "IsHoliday       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = train.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e585c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "features = pd.read_csv('features.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine the datasets\n",
    "combined = pd.concat([features, stores, train, test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ac5049a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.columns = combined.columns.str.strip()  # Remove any leading/trailing whitespace\n",
    "combined = combined.loc[:, ~combined.columns.duplicated()]  # Remove duplicate columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3567d814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers in each column:\n",
      "Store               0\n",
      "Temperature         7\n",
      "Fuel_Price          0\n",
      "MarkDown1         237\n",
      "MarkDown2         436\n",
      "MarkDown3         480\n",
      "MarkDown4         337\n",
      "MarkDown5         212\n",
      "CPI                 0\n",
      "Unemployment      386\n",
      "Size                0\n",
      "Dept                0\n",
      "Weekly_Sales    35521\n",
      "dtype: int64\n",
      "Length of mask: 421570\n",
      "Length of combined DataFrame: 421570\n",
      "Cleaned dataset:\n",
      "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2   \n",
      "0    1.0  2010-02-05        42.31       2.572        NaN        NaN  \\\n",
      "1    1.0  2010-02-12        38.51       2.548        NaN        NaN   \n",
      "2    1.0  2010-02-19        39.93       2.514        NaN        NaN   \n",
      "3    1.0  2010-02-26        46.63       2.561        NaN        NaN   \n",
      "4    1.0  2010-03-05        46.50       2.625        NaN        NaN   \n",
      "\n",
      "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment IsHoliday Type   \n",
      "0        NaN        NaN        NaN  211.096358         8.106     False    A  \\\n",
      "1        NaN        NaN        NaN  211.242170         8.106      True    A   \n",
      "2        NaN        NaN        NaN  211.289143         8.106     False    B   \n",
      "3        NaN        NaN        NaN  211.319643         8.106     False    A   \n",
      "4        NaN        NaN        NaN  211.350143         8.106     False    B   \n",
      "\n",
      "       Size  Dept  Weekly_Sales  \n",
      "0  151315.0     1      24924.50  \n",
      "1  202307.0     1      46039.49  \n",
      "2   37392.0     1      41595.55  \n",
      "3  205863.0     1      19403.54  \n",
      "4   34875.0     1      21827.90  \n"
     ]
    }
   ],
   "source": [
    "numeric_features = combined.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "\n",
    "# Compute IQR for outlier detection\n",
    "Q1 = numeric_features.quantile(0.25)\n",
    "Q3 = numeric_features.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Check for outliers\n",
    "outliers = (numeric_features < (Q1 - 1.5 * IQR)) | (numeric_features > (Q3 + 1.5 * IQR))\n",
    "outliers_mask = ~outliers.any(axis=1)\n",
    "\n",
    "# Display the number of outliers in each column\n",
    "print(\"Number of outliers in each column:\")\n",
    "print(outliers.sum())\n",
    "\n",
    "# Ensure that the boolean mask aligns with the DataFrame index\n",
    "print(\"Length of mask:\", len(outliers_mask))\n",
    "print(\"Length of combined DataFrame:\", len(combined))\n",
    "\n",
    "# Remove outliers from the combined dataset\n",
    "combined_no_outliers = combined[outliers_mask]\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(\"Cleaned dataset:\")\n",
    "print(combined_no_outliers.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9c30860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Store  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3   \n",
      "0 -12.993058    -8.680605  -15.525258  -0.018277   -0.02768  -0.031209  \\\n",
      "1 -12.993058   -10.306192  -15.932429  -0.018277   -0.02768  -0.031209   \n",
      "2 -12.993058    -9.698736  -16.509255  -0.018277   -0.02768  -0.031209   \n",
      "3 -12.993058    -6.832569  -15.711878  -0.018277   -0.02768  -0.031209   \n",
      "4 -12.993058    -6.888181  -14.626089  -0.018277   -0.02768  -0.031209   \n",
      "\n",
      "   MarkDown4  MarkDown5       CPI  Unemployment  ...  Date_2013-06-21   \n",
      "0  -0.025918    -0.0229  4.212300      2.361631  ...            False  \\\n",
      "1  -0.025918    -0.0229  4.240470      2.361631  ...            False   \n",
      "2  -0.025918    -0.0229  4.249545      2.361631  ...            False   \n",
      "3  -0.025918    -0.0229  4.255437      2.361631  ...            False   \n",
      "4  -0.025918    -0.0229  4.261330      2.361631  ...            False   \n",
      "\n",
      "   Date_2013-06-28  Date_2013-07-05  Date_2013-07-12  Date_2013-07-19   \n",
      "0            False            False            False            False  \\\n",
      "1            False            False            False            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   Date_2013-07-26  IsHoliday_True  Type_B  Type_C  Temperature_Fuel_Price  \n",
      "0            False           False   False   False              134.768635  \n",
      "1            False            True   False   False              164.202680  \n",
      "2            False           False    True   False              160.118907  \n",
      "3            False           False   False   False              107.352493  \n",
      "4            False           False    True   False              100.747150  \n",
      "\n",
      "[5 rows x 198 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Impute missing values\n",
    "numeric_data = combined_no_outliers.select_dtypes(include=['float64', 'int64'])\n",
    "categorical_data = combined_no_outliers.select_dtypes(include=['object'])\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "numeric_data_imputed = numeric_imputer.fit_transform(numeric_data)\n",
    "categorical_data_imputed = categorical_imputer.fit_transform(categorical_data)\n",
    "\n",
    "# Convert imputed data back to DataFrame\n",
    "numeric_data_imputed_df = pd.DataFrame(numeric_data_imputed, columns=numeric_data.columns, index=combined_no_outliers.index)\n",
    "categorical_data_imputed_df = pd.DataFrame(categorical_data_imputed, columns=categorical_data.columns, index=combined_no_outliers.index)\n",
    "\n",
    "# Concatenate the imputed data\n",
    "combined_imputed = pd.concat([numeric_data_imputed_df, categorical_data_imputed_df], axis=1)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_features = combined_imputed.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_scaled = scaler.fit_transform(numerical_features)\n",
    "\n",
    "numerical_scaled_df = pd.DataFrame(numerical_scaled, columns=numerical_features.columns, index=combined_imputed.index)\n",
    "combined_scaled = pd.concat([numerical_scaled_df, categorical_data_imputed_df], axis=1)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "combined_encoded = pd.get_dummies(combined_scaled, drop_first=True)\n",
    "\n",
    "# Feature Engineering example (create interaction features)\n",
    "combined_encoded['Temperature_Fuel_Price'] = combined_encoded['Temperature'] * combined_encoded['Fuel_Price']\n",
    "\n",
    "# Verify final dataset\n",
    "print(combined_encoded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6b47ba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['Price', 'Units_Sold', 'Revenue']\n"
     ]
    }
   ],
   "source": [
    "# Check for necessary columns\n",
    "required_columns = ['Price', 'Units_Sold', 'Revenue']\n",
    "missing_columns = [col for col in required_columns if col not in combined.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All necessary columns are present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ce47d60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2',\n",
       "       'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment',\n",
       "       'IsHoliday', 'Type', 'Size', 'Dept', 'Weekly_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_no_outliers.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a213b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
